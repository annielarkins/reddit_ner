{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dictionaryCheck.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVqiIyviToFl",
        "outputId": "23659193-f272-49b9-acb5-41f839d4b64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MerWebPy\n",
            "  Downloading MerWebPy-1.0.0-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from MerWebPy) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->MerWebPy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->MerWebPy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->MerWebPy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->MerWebPy) (2.10)\n",
            "Installing collected packages: MerWebPy\n",
            "Successfully installed MerWebPy-1.0.0\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from nltk.corpus import words\n",
        "import nltk\n",
        "#!pip install MerWebPy\n",
        "#nltk.download('all')\n",
        "\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "!pip install -qq pyenchant\n",
        "import enchant\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "abstract1 = \"\"\"Many algorithms have been recently developed for reducing dimensionality by projecting data onto an intrinsic non-linear manifold. Unfortunately, existing algorithms often lose significant precision in this transformation. Manifold Sculpting is a new algorithm that iteratively reduces dimensionality by simulating surface tension in local neighborhoods. We present several experiments that show Manifold Sculpting yields more accurate results than existing algorithms with both generated and natural data-sets. Manifold Sculpting is also able to benefit from both prior dimensionality reduction efforts.\"\"\"\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n"
      ],
      "metadata": {
        "id": "lmVdcFG2XYKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for stemming\n",
        "def get_lemm(text):\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    print(wordnet_lemmatizer.lemmatize('developed'))\n",
        "    #print (wordnet_lemmatizer.lemmatize(\"geese\"))\n",
        "    text = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    print([wordnet_lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "\n",
        "abstract1 = get_lemm(abstract1)\n",
        "\n",
        "abstract_lower = abstract1.lower()\n",
        "\n",
        "# initializing punctuations string\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        " \n",
        "# Removing punctuations in string\n",
        "# Using loop + punctuation string\n",
        "for ele in abstract_lower:\n",
        "    if ele in punc:\n",
        "        abstract_lower = abstract_lower.replace(ele, \"\")\n",
        "\n",
        "res = abstract_lower.split() \n",
        "\n",
        "# printing result \n",
        "#for i in res:\n",
        "  #if not (i in words.words()):\n",
        "    #print(i)\n",
        "\n",
        "for i in res:\n",
        "  d = enchant.Dict(\"en_US\")\n",
        "  if (not (d.check(i))):\n",
        "    print(i)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPdmbAFkW_Kv",
        "outputId": "6c7f4f7a-5f38-40bb-ca3f-05963c2f4620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "developed\n",
            "['Many', 'algorithm', 'have', 'been', 'recently', 'developed', 'for', 'reducing', 'dimensionality', 'by', 'projecting', 'data', 'onto', 'an', 'intrinsic', 'non-linear', 'manifold.', 'Unfortunately,', 'existing', 'algorithm', 'often', 'lose', 'significant', 'precision', 'in', 'this', 'transformation.', 'Manifold', 'Sculpting', 'is', 'a', 'new', 'algorithm', 'that', 'iteratively', 'reduces', 'dimensionality', 'by', 'simulating', 'surface', 'tension', 'in', 'local', 'neighborhoods.', 'We', 'present', 'several', 'experiment', 'that', 'show', 'Manifold', 'Sculpting', 'yield', 'more', 'accurate', 'result', 'than', 'existing', 'algorithm', 'with', 'both', 'generated', 'and', 'natural', 'data-sets.', 'Manifold', 'Sculpting', 'is', 'also', 'able', 'to', 'benefit', 'from', 'both', 'prior', 'dimensionality', 'reduction', 'efforts.']\n",
            "dimensionality\n",
            "iteratively\n",
            "dimensionality\n",
            "datasets\n",
            "dimensionality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTXkEwloS1Xs",
        "outputId": "c3039db3-f705-4d5d-f2c0-3fc1a8d57730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoW3kH7zS9BM",
        "outputId": "3614dcb6-093f-4d78-a7e1-6528a5401ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}